{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "#VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from cfg import Config\n",
    "import pickle\n",
    "\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Users/ACER/Desktop/hpc_dataset/'\n",
    "training_dir = input_dir + 'train/'\n",
    "\n",
    "for img in os.listdir(training_dir):\n",
    "    img_array = cv2.imread(os.path.join(training_dir,img)) \n",
    "    plt.imshow(img_array,cmap=\"gray\")#what is cmap?\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape)\n",
    "print(img_array.dtype)\n",
    "#img_array = img_array/255\n",
    "#print(img_array.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels. source:Seth Adams\n",
    "df = pd.read_csv('/Users/ACER/Desktop/hpc_dataset/train_labels.csv')\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "\n",
    "def build_training_data():\n",
    "    X = []\n",
    "    y = []\n",
    "    classes = [0,1]\n",
    "    \n",
    "    for img in tqdm(os.listdir(training_dir)[:2000]):\n",
    "        img_array = cv2.imread(os.path.join(training_dir,img)) \n",
    "        img_array = img_array/255\n",
    "        img = img.replace('.tif','')\n",
    "        label = df.at[img, 'label']\n",
    "        X.append(img_array)\n",
    "        y.append(classes.index(label))\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out_X = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out_X)\n",
    "pickle_out_X.close()\n",
    "\n",
    "pickle_out_y = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out_y)\n",
    "pickle_out_y.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_model():\n",
    "    base_model = VGG16(include_top=False,\n",
    "                       pooling='avg',\n",
    "                       input_shape = (96,96,3),\n",
    "                       weights = 'imagenet')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(256,activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(128,activation='sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.layers[0].trainable=False\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = VGG16_model()\n",
    "model.fit(X, y, epochs=3, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Save the best model\n",
    "model_file = \"model.h5\"\n",
    "ModelCheckpoint(model_file, monitor='val_acc',\n",
    "                verbose=1, save_best_only=True,\n",
    "                mode='max')\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
