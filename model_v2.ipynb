{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob \n",
    "from skimage.io import imread \n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "#!pip install livelossplot\n",
    "from livelossplot import PlotLossesKeras\n",
    "import cv2\n",
    "\n",
    "#VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Users/ACER/Desktop/hpc_dataset/'\n",
    "training_dir = input_dir + 'train/'\n",
    "\n",
    "for img in os.listdir(training_dir):\n",
    "    img_array = cv2.imread(os.path.join(training_dir,img)) \n",
    "    plt.imshow(img_array,cmap=\"gray\")#what is cmap?\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
    "MODEL_PLOT_FILE = \"model_plot.png\"\n",
    "MODEL_FILE = \"model.h5\"\n",
    "TRAINING_PLOT_FILE = \"training.png\"\n",
    "VALIDATION_PLOT_FILE = \"validation.png\"\n",
    "ROC_PLOT_FILE = \"roc.png\"\n",
    "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "SAMPLE_COUNT = 85000\n",
    "TRAINING_RATIO = 0.9\n",
    "IMAGE_SIZE = 96\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 192\n",
    "VERBOSITY = 1\n",
    "TESTING_BATCH_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels. source:Seth Adams\n",
    "df = pd.read_csv('/Users/ACER/Desktop/hpc_dataset/train_labels.csv')\n",
    "df.set_index('fname', inplace=True)\n",
    "\n",
    "# Sentdex\n",
    "training_data = []\n",
    "\n",
    "def build_training_data():\n",
    "    for img in os.listdir(training_dir):\n",
    "        img_array = cv2.imread(os.path.join(training_dir,img)) \n",
    "        label = df.at[img_array, 'label']\n",
    "        training_data.append(img_array)\n",
    "        labels.append(classes.index(label))\n",
    "    \n",
    "    return training_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_model:\n",
    "    base_model = VGG16(include_top=False,\n",
    "                       input_shape = (96,96,3),\n",
    "                       weights = 'imagenet')\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation='sigmoid'))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "                  metrics=['acc'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_training_data()\n",
    "y_flat = np.argmax(y, axis=1) #return the index value\n",
    "model = VGG16_model()\n",
    "\n",
    "class_weight = compute_class_weight('balanced', \n",
    "                                    np.unique(y_flat),\n",
    "                                    y_flat)\n",
    "\n",
    "checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc', verbose=1, mode='max',\n",
    "                             save_best_only=True, save_weights_only=False, period=1)\n",
    "\n",
    "history = model.fit(X, y, epochs=1000, batch_size=200, \n",
    "          shuffle=True, validation_split=0.1,\n",
    "          callbacks = [checkpoint])\n",
    "\n",
    "model.save(config.model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
