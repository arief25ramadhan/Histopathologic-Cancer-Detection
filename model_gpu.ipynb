{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.1.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#VGG16\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from cfg import Config\n",
    "import pickle\n",
    "\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Users/ACER/Desktop/hpc_dataset/'\n",
    "visual_dir = input_dir + 'train/1'\n",
    "train_dir = input_dir + 'train/'\n",
    "val_dir = input_dir + 'val/'\n",
    "\n",
    "for img in os.listdir(visual_dir):\n",
    "    img_array = cv2.imread(os.path.join(visual_dir,img)).astype(np.float32)\n",
    "    img_array = img_array/255.0\n",
    "    plt.imshow(img_array,cmap=\"gray\")#what is cmap?\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "training_data_generator = ImageDataGenerator( rescale=1./255,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             rotation_range=90,\n",
    "                                             zoom_range=0.2, \n",
    "                                             width_shift_range=0.1,\n",
    "                                             height_shift_range=0.1,\n",
    "                                             shear_range=0.05,\n",
    "                                             channel_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "training_generator = training_data_generator.flow_from_directory(train_dir,\n",
    "                                                                 target_size=(96,96),\n",
    "                                                                 batch_size=64,\n",
    "                                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = val_data_generator.flow_from_directory(val_dir,\n",
    "                                                              target_size=(96,96),\n",
    "                                                              batch_size=64,\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_model():\n",
    "    base_model = VGG16(include_top=False,\n",
    "                       input_shape = (96,96,3),\n",
    "                       weights = 'imagenet')\n",
    "\n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        print(layer,layer.trainable)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #model.layers[0].trainable=False\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer=Adam(lr=0.0002),\n",
    "                  metrics=['acc'] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(training_generator,\n",
    "                        steps_per_epoch=len(training_generator), \n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        epochs=1,\n",
    "                        verbose=1)\n",
    "# Save the best model\n",
    "model_file = \"models/model_v1.h5\"\n",
    "ModelCheckpoint(model_file, monitor='val_acc',\n",
    "                verbose=1, save_best_only=True,\n",
    "                mode='max')\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 58/58 [40:54<00:00, 42.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/model_v1.h5\")\n",
    "\n",
    "from skimage.io import imread\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "testing_batch_size = 1000\n",
    "\n",
    "testing_files = glob(os.path.join('/Users/ACER/Desktop/hpc_dataset/test/','*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "for index in tqdm(range(0, len(testing_files), testing_batch_size)):\n",
    "    data_frame = pd.DataFrame({'path': testing_files[index:index+testing_batch_size]})\n",
    "    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    data_frame['image'] = data_frame['path'].map(imread)\n",
    "    images = np.stack(data_frame.image, axis=0)\n",
    "    predicted_labels = [model.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n",
    "    predictions = np.array(predicted_labels)\n",
    "    data_frame['label'] = predictions\n",
    "    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n",
    "submission.to_csv(\"submission_ar_8.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
