{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from glob import glob \n",
    "from skimage.io import imread \n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Average, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "#!pip install livelossplot\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
    "MODEL_PLOT_FILE = \"model_plot.png\"\n",
    "MODEL_FILE = \"model.h5\"\n",
    "TRAINING_PLOT_FILE = \"training.png\"\n",
    "VALIDATION_PLOT_FILE = \"validation.png\"\n",
    "ROC_PLOT_FILE = \"roc.png\"\n",
    "KAGGLE_SUBMISSION_FILE = \"kaggle_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "SAMPLE_COUNT = 85000\n",
    "TRAINING_RATIO = 0.9\n",
    "IMAGE_SIZE = 96\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 192\n",
    "VERBOSITY = 1\n",
    "TESTING_BATCH_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory\n",
    "input_dir = '/Users/ACER/Desktop/hpc_dataset/'\n",
    "training_dir = input_dir + 'train/'\n",
    "data_frame = pd.DataFrame({'path': glob(os.path.join(training_dir,'*.tif'))})\n",
    "data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[6].split('.')[0])\n",
    "labels = pd.read_csv(input_dir + 'train_labels.csv')\n",
    "data_frame = data_frame.merge(labels, on='id')\n",
    "negatives = data_frame[data_frame.label == 0].sample(SAMPLE_COUNT)\n",
    "positives = data_frame[data_frame.label == 1].sample(SAMPLE_COUNT)\n",
    "data_frame = pd.concat([negatives, positives]).reset_index()\n",
    "data_frame = data_frame[['path', 'id', 'label']]\n",
    "data_frame['image'] = data_frame['path'].map(imread)\n",
    "\n",
    "training_path = '../training'\n",
    "validation_path = '../validation'\n",
    "\n",
    "for folder in [training_path, validation_path]:\n",
    "    for subfolder in ['0', '1']:\n",
    "        path = os.path.join(folder, subfolder)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "training, validation = train_test_split(data_frame, train_size=TRAINING_RATIO, stratify=data_frame['label'])\n",
    "\n",
    "data_frame.set_index('id', inplace=True)\n",
    "\n",
    "for images_and_path in [(training, training_path), (validation, validation_path)]:\n",
    "    images = images_and_path[0]\n",
    "    path = images_and_path[1]\n",
    "    for image in images['id'].values:\n",
    "        file_name = image + '.tif'\n",
    "        label = str(data_frame.loc[image,'label'])\n",
    "        destination = os.path.join(path, label, file_name)\n",
    "        if not os.path.exists(destination):\n",
    "            source = os.path.join(input_dir + 'train', file_name)\n",
    "            shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "training_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             rotation_range=180,\n",
    "                                             zoom_range=0.4, \n",
    "                                             width_shift_range=0.3,\n",
    "                                             height_shift_range=0.3,\n",
    "                                             shear_range=0.3,\n",
    "                                             channel_shift_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation\n",
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                 target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 class_mode='binary')\n",
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                              target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                              batch_size=BATCH_SIZE,\n",
    "                                                                              class_mode='binary')\n",
    "testing_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                           target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                           batch_size=BATCH_SIZE,\n",
    "                                                                           class_mode='binary',\n",
    "                                                                           shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
